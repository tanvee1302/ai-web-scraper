import streamlit as st
from scrape import scrape_website, split_dom_Content, clean_body_content, extract_body_content
from parse import parse_with_ollama

st.set_page_config(page_title="AI Web Scraper", layout="wide")
st.title("ğŸ•¸ï¸ AI Web Scraper with LLaMA3")

# Input: URL
url = st.text_input("ğŸŒ Enter a website URL")

# Scrape button
if st.button("ğŸš€ Scrape Site"):
    if url:
        st.write("ğŸ”„ Scraping the website...")
        result = scrape_website(url)
        body_content = extract_body_content(result)
        cleaned_content = clean_body_content(body_content)
        st.session_state.dom_content = cleaned_content

        with st.expander("ğŸ§¾ View Raw DOM Content"):
            st.text_area("DOM Content", cleaned_content, height=300)
    else:
        st.warning("âš ï¸ Please enter a valid URL.")

# If DOM content is available, show parsing options
if "dom_content" in st.session_state:
    st.markdown("---")
    st.subheader("ğŸ” Extract Specific Info from DOM")

    parse_description = st.text_area("âœï¸ What information do you want to extract?")
    if st.button("ğŸ§  Parse with LLaMA3"):
        if parse_description.strip() == "":
            st.warning("âš ï¸ Please describe what to extract.")
        else:
            st.info("Calling LLaMA3 to parse content...")
            dom_chunks = split_dom_Content(st.session_state.dom_content)
            result = parse_with_ollama(dom_chunks, parse_description)
            st.success("âœ… Extraction Complete")
            st.text_area("ğŸ“¤ Extracted Result", result, height=200)
